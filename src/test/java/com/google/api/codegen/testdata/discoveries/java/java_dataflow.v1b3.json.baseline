
/*
 * PRE-REQUISITES:
 * ---------------
 * 1. If not already done, enable the Google Dataflow API and check quota for your project at
 *    https://console.developers.google.com/apis/api/dataflow_component/quotas
 * 2. To install the client library on Maven or Gradle, check installation instructions at
 *    https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataflow/v1b3/java
 * 3. This sample uses Application Default Credentials for Auth.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run 'gcloud beta auth application-default login'
 */

import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataflow.Dataflow;
import com.google.api.services.dataflow.model.Job;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Collections;



public class DataflowExample {
  public static void main(String[] args) throws IOException, GeneralSecurityException {
    // Authentication is provided by the 'gcloud' tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    // The createScopedRequired method returns true when running on GAE or a local developer
    // machine. In that case, the desired scopes must be passed in manually. When the code is
    // running in GCE, GKE or a Managed VM, the scopes are pulled from the GCE metadata server.
    // For more information, see
    // https://developers.google.com/identity/protocols/application-default-credentials
    if (credential.createScopedRequired()) {
      credential = credential.createScoped(Collections.singletonList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();
    Dataflow dataflowService = new Dataflow.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // TODO: Change placeholders below to appropriate parameter values for the 'create' method:
    // The project which owns the job.
    String projectId = "";

    Job content = new Job();
    // TODO: Add code here to assign values to desired fields of the 'content' object

    Dataflow.Projects.Jobs.Create request = dataflowService.projects().jobs().create(projectId, content);
    Job response = request.execute();

    // TODO: Add code here to process the 'response' object
  }
}
/*
 * PRE-REQUISITES:
 * ---------------
 * 1. If not already done, enable the Google Dataflow API and check quota for your project at
 *    https://console.developers.google.com/apis/api/dataflow_component/quotas
 * 2. To install the client library on Maven or Gradle, check installation instructions at
 *    https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataflow/v1b3/java
 * 3. This sample uses Application Default Credentials for Auth.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run 'gcloud beta auth application-default login'
 */

import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataflow.Dataflow;
import com.google.api.services.dataflow.model.Job;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Collections;



public class DataflowExample {
  public static void main(String[] args) throws IOException, GeneralSecurityException {
    // Authentication is provided by the 'gcloud' tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    // The createScopedRequired method returns true when running on GAE or a local developer
    // machine. In that case, the desired scopes must be passed in manually. When the code is
    // running in GCE, GKE or a Managed VM, the scopes are pulled from the GCE metadata server.
    // For more information, see
    // https://developers.google.com/identity/protocols/application-default-credentials
    if (credential.createScopedRequired()) {
      credential = credential.createScoped(Collections.singletonList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();
    Dataflow dataflowService = new Dataflow.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // TODO: Change placeholders below to appropriate parameter values for the 'get' method:
    // The project which owns the job.
    String projectId = "";
    // Identifies a single job.
    String jobId = "";

    Dataflow.Projects.Jobs.Get request = dataflowService.projects().jobs().get(projectId, jobId);
    Job response = request.execute();

    // TODO: Add code here to process the 'response' object
  }
}
/*
 * PRE-REQUISITES:
 * ---------------
 * 1. If not already done, enable the Google Dataflow API and check quota for your project at
 *    https://console.developers.google.com/apis/api/dataflow_component/quotas
 * 2. To install the client library on Maven or Gradle, check installation instructions at
 *    https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataflow/v1b3/java
 * 3. This sample uses Application Default Credentials for Auth.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run 'gcloud beta auth application-default login'
 */

import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataflow.Dataflow;
import com.google.api.services.dataflow.model.JobMetrics;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Collections;



public class DataflowExample {
  public static void main(String[] args) throws IOException, GeneralSecurityException {
    // Authentication is provided by the 'gcloud' tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    // The createScopedRequired method returns true when running on GAE or a local developer
    // machine. In that case, the desired scopes must be passed in manually. When the code is
    // running in GCE, GKE or a Managed VM, the scopes are pulled from the GCE metadata server.
    // For more information, see
    // https://developers.google.com/identity/protocols/application-default-credentials
    if (credential.createScopedRequired()) {
      credential = credential.createScoped(Collections.singletonList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();
    Dataflow dataflowService = new Dataflow.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // TODO: Change placeholders below to appropriate parameter values for the 'getMetrics' method:
    // A project id.
    String projectId = "";
    // The job to get messages for.
    String jobId = "";

    Dataflow.Projects.Jobs.GetMetrics request = dataflowService.projects().jobs().getMetrics(projectId, jobId);
    JobMetrics response = request.execute();

    // TODO: Add code here to process the 'response' object
  }
}
/*
 * PRE-REQUISITES:
 * ---------------
 * 1. If not already done, enable the Google Dataflow API and check quota for your project at
 *    https://console.developers.google.com/apis/api/dataflow_component/quotas
 * 2. To install the client library on Maven or Gradle, check installation instructions at
 *    https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataflow/v1b3/java
 * 3. This sample uses Application Default Credentials for Auth.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run 'gcloud beta auth application-default login'
 */

import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataflow.Dataflow;
import com.google.api.services.dataflow.model.Job;
import com.google.api.services.dataflow.model.ListJobsResponse;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Collections;



public class DataflowExample {
  public static void main(String[] args) throws IOException, GeneralSecurityException {
    // Authentication is provided by the 'gcloud' tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    // The createScopedRequired method returns true when running on GAE or a local developer
    // machine. In that case, the desired scopes must be passed in manually. When the code is
    // running in GCE, GKE or a Managed VM, the scopes are pulled from the GCE metadata server.
    // For more information, see
    // https://developers.google.com/identity/protocols/application-default-credentials
    if (credential.createScopedRequired()) {
      credential = credential.createScoped(Collections.singletonList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();
    Dataflow dataflowService = new Dataflow.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // TODO: Change placeholders below to appropriate parameter values for the 'list' method:
    // The project which owns the jobs.
    String projectId = "";

    Dataflow.Projects.Jobs.List request = dataflowService.projects().jobs().list(projectId);
    ListJobsResponse response;
    do {
      response = request.execute();
      if (response.getJobs() == null)
        continue;

      for (Job job : response.getJobs()) {
        // TODO: Add code here to process each 'job' resource
      }

      request.setPageToken(response.getNextPageToken());
    } while (response.getNextPageToken() != null);
  }
}
/*
 * PRE-REQUISITES:
 * ---------------
 * 1. If not already done, enable the Google Dataflow API and check quota for your project at
 *    https://console.developers.google.com/apis/api/dataflow_component/quotas
 * 2. To install the client library on Maven or Gradle, check installation instructions at
 *    https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataflow/v1b3/java
 * 3. This sample uses Application Default Credentials for Auth.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run 'gcloud beta auth application-default login'
 */

import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataflow.Dataflow;
import com.google.api.services.dataflow.model.JobMessage;
import com.google.api.services.dataflow.model.ListJobMessagesResponse;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Collections;



public class DataflowExample {
  public static void main(String[] args) throws IOException, GeneralSecurityException {
    // Authentication is provided by the 'gcloud' tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    // The createScopedRequired method returns true when running on GAE or a local developer
    // machine. In that case, the desired scopes must be passed in manually. When the code is
    // running in GCE, GKE or a Managed VM, the scopes are pulled from the GCE metadata server.
    // For more information, see
    // https://developers.google.com/identity/protocols/application-default-credentials
    if (credential.createScopedRequired()) {
      credential = credential.createScoped(Collections.singletonList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();
    Dataflow dataflowService = new Dataflow.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // TODO: Change placeholders below to appropriate parameter values for the 'list' method:
    // A project id.
    String projectId = "";
    // The job to get messages about.
    String jobId = "";

    Dataflow.Projects.Jobs.Messages.List request = dataflowService.projects().jobs().messages().list(projectId, jobId);
    ListJobMessagesResponse response;
    do {
      response = request.execute();
      if (response.getJobMessages() == null)
        continue;

      for (JobMessage jobMessage : response.getJobMessages()) {
        // TODO: Add code here to process each 'jobMessage' resource
      }

      request.setPageToken(response.getNextPageToken());
    } while (response.getNextPageToken() != null);
  }
}
/*
 * PRE-REQUISITES:
 * ---------------
 * 1. If not already done, enable the Google Dataflow API and check quota for your project at
 *    https://console.developers.google.com/apis/api/dataflow_component/quotas
 * 2. To install the client library on Maven or Gradle, check installation instructions at
 *    https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataflow/v1b3/java
 * 3. This sample uses Application Default Credentials for Auth.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run 'gcloud beta auth application-default login'
 */

import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataflow.Dataflow;
import com.google.api.services.dataflow.model.Job;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Collections;



public class DataflowExample {
  public static void main(String[] args) throws IOException, GeneralSecurityException {
    // Authentication is provided by the 'gcloud' tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    // The createScopedRequired method returns true when running on GAE or a local developer
    // machine. In that case, the desired scopes must be passed in manually. When the code is
    // running in GCE, GKE or a Managed VM, the scopes are pulled from the GCE metadata server.
    // For more information, see
    // https://developers.google.com/identity/protocols/application-default-credentials
    if (credential.createScopedRequired()) {
      credential = credential.createScoped(Collections.singletonList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();
    Dataflow dataflowService = new Dataflow.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // TODO: Change placeholders below to appropriate parameter values for the 'update' method:
    // The project which owns the job.
    String projectId = "";
    // Identifies a single job.
    String jobId = "";

    Job content = new Job();
    // TODO: Add code here to assign values to desired fields of the 'content' object

    Dataflow.Projects.Jobs.Update request = dataflowService.projects().jobs().update(projectId, jobId, content);
    Job response = request.execute();

    // TODO: Add code here to process the 'response' object
  }
}
/*
 * PRE-REQUISITES:
 * ---------------
 * 1. If not already done, enable the Google Dataflow API and check quota for your project at
 *    https://console.developers.google.com/apis/api/dataflow_component/quotas
 * 2. To install the client library on Maven or Gradle, check installation instructions at
 *    https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataflow/v1b3/java
 * 3. This sample uses Application Default Credentials for Auth.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run 'gcloud beta auth application-default login'
 */

import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataflow.Dataflow;
import com.google.api.services.dataflow.model.LeaseWorkItemRequest;
import com.google.api.services.dataflow.model.LeaseWorkItemResponse;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Collections;



public class DataflowExample {
  public static void main(String[] args) throws IOException, GeneralSecurityException {
    // Authentication is provided by the 'gcloud' tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    // The createScopedRequired method returns true when running on GAE or a local developer
    // machine. In that case, the desired scopes must be passed in manually. When the code is
    // running in GCE, GKE or a Managed VM, the scopes are pulled from the GCE metadata server.
    // For more information, see
    // https://developers.google.com/identity/protocols/application-default-credentials
    if (credential.createScopedRequired()) {
      credential = credential.createScoped(Collections.singletonList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();
    Dataflow dataflowService = new Dataflow.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // TODO: Change placeholders below to appropriate parameter values for the 'lease' method:
    // Identifies the project this worker belongs to.
    String projectId = "";
    // Identifies the workflow job this worker belongs to.
    String jobId = "";

    LeaseWorkItemRequest content = new LeaseWorkItemRequest();
    // TODO: Add code here to assign values to desired fields of the 'content' object

    Dataflow.Projects.Jobs.WorkItems.Lease request = dataflowService.projects().jobs().workItems().lease(projectId, jobId, content);
    LeaseWorkItemResponse response = request.execute();

    // TODO: Add code here to process the 'response' object
  }
}
/*
 * PRE-REQUISITES:
 * ---------------
 * 1. If not already done, enable the Google Dataflow API and check quota for your project at
 *    https://console.developers.google.com/apis/api/dataflow_component/quotas
 * 2. To install the client library on Maven or Gradle, check installation instructions at
 *    https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataflow/v1b3/java
 * 3. This sample uses Application Default Credentials for Auth.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run 'gcloud beta auth application-default login'
 */

import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataflow.Dataflow;
import com.google.api.services.dataflow.model.ReportWorkItemStatusRequest;
import com.google.api.services.dataflow.model.ReportWorkItemStatusResponse;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Collections;



public class DataflowExample {
  public static void main(String[] args) throws IOException, GeneralSecurityException {
    // Authentication is provided by the 'gcloud' tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    // The createScopedRequired method returns true when running on GAE or a local developer
    // machine. In that case, the desired scopes must be passed in manually. When the code is
    // running in GCE, GKE or a Managed VM, the scopes are pulled from the GCE metadata server.
    // For more information, see
    // https://developers.google.com/identity/protocols/application-default-credentials
    if (credential.createScopedRequired()) {
      credential = credential.createScoped(Collections.singletonList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();
    Dataflow dataflowService = new Dataflow.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // TODO: Change placeholders below to appropriate parameter values for the 'reportStatus' method:
    // The project which owns the WorkItem's job.
    String projectId = "";
    // The job which the WorkItem is part of.
    String jobId = "";

    ReportWorkItemStatusRequest content = new ReportWorkItemStatusRequest();
    // TODO: Add code here to assign values to desired fields of the 'content' object

    Dataflow.Projects.Jobs.WorkItems.ReportStatus request = dataflowService.projects().jobs().workItems().reportStatus(projectId, jobId, content);
    ReportWorkItemStatusResponse response = request.execute();

    // TODO: Add code here to process the 'response' object
  }
}
/*
 * PRE-REQUISITES:
 * ---------------
 * 1. If not already done, enable the Google Dataflow API and check quota for your project at
 *    https://console.developers.google.com/apis/api/dataflow_component/quotas
 * 2. To install the client library on Maven or Gradle, check installation instructions at
 *    https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataflow/v1b3/java
 * 3. This sample uses Application Default Credentials for Auth.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run 'gcloud beta auth application-default login'
 */

import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataflow.Dataflow;
import com.google.api.services.dataflow.model.SendWorkerMessagesRequest;
import com.google.api.services.dataflow.model.SendWorkerMessagesResponse;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Collections;



public class DataflowExample {
  public static void main(String[] args) throws IOException, GeneralSecurityException {
    // Authentication is provided by the 'gcloud' tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    // The createScopedRequired method returns true when running on GAE or a local developer
    // machine. In that case, the desired scopes must be passed in manually. When the code is
    // running in GCE, GKE or a Managed VM, the scopes are pulled from the GCE metadata server.
    // For more information, see
    // https://developers.google.com/identity/protocols/application-default-credentials
    if (credential.createScopedRequired()) {
      credential = credential.createScoped(Collections.singletonList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();
    Dataflow dataflowService = new Dataflow.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // TODO: Change placeholders below to appropriate parameter values for the 'workerMessages' method:
    // The project to send the WorkerMessages to.
    String projectId = "";

    SendWorkerMessagesRequest content = new SendWorkerMessagesRequest();
    // TODO: Add code here to assign values to desired fields of the 'content' object

    Dataflow.Projects.WorkerMessages request = dataflowService.projects().workerMessages(projectId, content);
    SendWorkerMessagesResponse response = request.execute();

    // TODO: Add code here to process the 'response' object
  }
}
