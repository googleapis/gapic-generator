
/*
 * BEFORE RUNNING:
 * ---------------
 * 1. If not already done, enable the Google Cloud Dataproc API
 *    and check the quota for your project at
 *    https://console.developers.google.com/apis/api/dataproc
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35
 * 2. Install the Java client library on Maven or Gradle. Check installation
=======
 * 2. This sample uses Application Default Credentials for authentication.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run
 *    'gcloud beta auth application-default login'
 * 3. Install the Java client library on maven or gradle. Check installation
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
 *    instructions at https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataproc/v1/java
 */
import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataproc.Dataproc;
import com.google.api.services.dataproc.Dataproc.Projects.Regions.Clusters.Create;
import com.google.api.services.dataproc.model.Cluster;
import com.google.api.services.dataproc.model.Operation;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Arrays;


public class DataprocExample {
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35
  public void run() throws IOException, GeneralSecurityException {
    // TODO: Assign desired fields.
    Cluster requestBody = new Cluster();

    // [Required] The ID of the Google Cloud Platform project that the cluster belongs to.
    String projectId = ""; // TODO: Update field(s).

    // [Required] The Cloud Dataproc region in which to handle the request.
    String region = ""; // TODO: Update field(s).

    Dataproc service = createService();
    Create request = service.projects().regions().clusters().create(projectId, region, requestBody);
    Operation response = request.execute();
    System.out.println(response);
  }

  public Dataproc createService() throws IOException, GeneralSecurityException {
    // TODO: This sample uses Application Default Credentials for authentication.
    // Install the gcloud CLI from https://cloud.google.com/sdk and run
    // `gcloud beta auth application-default login`
=======
  public static void main(String[] args) throws IOException, GeneralSecurityException {

    // Authentication is provided by the 'gcloud' tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    if (credential.createScopedRequired()) {
      credential =
          credential.createScoped(Arrays.asList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35

    return new Dataproc.Builder(httpTransport, jsonFactory, credential)
        .setApplicationName("Sample")
        .build();
  }

  public static void main(String[] args) throws IOException, GeneralSecurityException {
    try {
      new DataprocExample().run();
    } catch (IOException e) {
      System.out.println(e.getMessage());
    } catch (GeneralSecurityException e) {
      System.out.println(e.getMessage());
    }
=======
    Dataproc dataprocService = new Dataproc.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // TODO: Change placeholders below to appropriate parameter values for the 'create' method:

    // * [Required] The ID of the Google Cloud Platform project that the cluster belongs to.
    String projectId = "{MY-PROJECT-ID}";

    // * [Required] The Cloud Dataproc region in which to handle the request.
    String region = "{MY-REGION}";

    Cluster content = new Cluster();
    // TODO: Add code here to assign values to desired fields of the 'content' object

    Dataproc.Projects.Regions.Clusters.Create request = dataprocService.projects().regions().clusters().create(projectId, region, content);
    Operation response = request.execute();

    // TODO: Add code here to process the 'response' object
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
  }
}
/*
 * BEFORE RUNNING:
 * ---------------
 * 1. If not already done, enable the Google Cloud Dataproc API
 *    and check the quota for your project at
 *    https://console.developers.google.com/apis/api/dataproc
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35
 * 2. Install the Java client library on Maven or Gradle. Check installation
=======
 * 2. This sample uses Application Default Credentials for authentication.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run
 *    'gcloud beta auth application-default login'
 * 3. Install the Java client library on maven or gradle. Check installation
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
 *    instructions at https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataproc/v1/java
 */
import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataproc.Dataproc;
import com.google.api.services.dataproc.Dataproc.Projects.Regions.Clusters.Delete;
import com.google.api.services.dataproc.model.Operation;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Arrays;


public class DataprocExample {
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35
  public void run() throws IOException, GeneralSecurityException {
    // [Required] The ID of the Google Cloud Platform project that the cluster belongs to.
    String projectId = ""; // TODO: Update field(s).

    // [Required] The Cloud Dataproc region in which to handle the request.
    String region = ""; // TODO: Update field(s).

    // [Required] The cluster name.
    String clusterName = ""; // TODO: Update field(s).

    Dataproc service = createService();
    Delete request = service.projects().regions().clusters().delete(projectId, region, clusterName);
    Operation response = request.execute();
    System.out.println(response);
  }

  public Dataproc createService() throws IOException, GeneralSecurityException {
    // TODO: This sample uses Application Default Credentials for authentication.
    // Install the gcloud CLI from https://cloud.google.com/sdk and run
    // `gcloud beta auth application-default login`
=======
  public static void main(String[] args) throws IOException, GeneralSecurityException {

    // Authentication is provided by the 'gcloud' tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    if (credential.createScopedRequired()) {
      credential =
          credential.createScoped(Arrays.asList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35

    return new Dataproc.Builder(httpTransport, jsonFactory, credential)
        .setApplicationName("Sample")
        .build();
  }

  public static void main(String[] args) throws IOException, GeneralSecurityException {
    try {
      new DataprocExample().run();
    } catch (IOException e) {
      System.out.println(e.getMessage());
    } catch (GeneralSecurityException e) {
      System.out.println(e.getMessage());
    }
=======
    Dataproc dataprocService = new Dataproc.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // TODO: Change placeholders below to appropriate parameter values for the 'delete' method:

    // * [Required] The ID of the Google Cloud Platform project that the cluster belongs to.
    String projectId = "{MY-PROJECT-ID}";

    // * [Required] The Cloud Dataproc region in which to handle the request.
    String region = "{MY-REGION}";

    // * [Required] The cluster name.
    String clusterName = "{MY-CLUSTER-NAME}";

    Dataproc.Projects.Regions.Clusters.Delete request = dataprocService.projects().regions().clusters().delete(projectId, region, clusterName);
    Operation response = request.execute();

    // TODO: Add code here to process the 'response' object
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
  }
}
/*
 * BEFORE RUNNING:
 * ---------------
 * 1. If not already done, enable the Google Cloud Dataproc API
 *    and check the quota for your project at
 *    https://console.developers.google.com/apis/api/dataproc
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35
 * 2. Install the Java client library on Maven or Gradle. Check installation
=======
 * 2. This sample uses Application Default Credentials for authentication.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run
 *    'gcloud beta auth application-default login'
 * 3. Install the Java client library on maven or gradle. Check installation
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
 *    instructions at https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataproc/v1/java
 */
import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataproc.Dataproc;
import com.google.api.services.dataproc.Dataproc.Projects.Regions.Clusters.Diagnose;
import com.google.api.services.dataproc.model.DiagnoseClusterRequest;
import com.google.api.services.dataproc.model.Operation;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Arrays;


public class DataprocExample {
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35
  public void run() throws IOException, GeneralSecurityException {
    // TODO: Assign desired fields.
    DiagnoseClusterRequest requestBody = new DiagnoseClusterRequest();

    // [Required] The ID of the Google Cloud Platform project that the cluster belongs to.
    String projectId = ""; // TODO: Update field(s).

    // [Required] The Cloud Dataproc region in which to handle the request.
    String region = ""; // TODO: Update field(s).

    // [Required] The cluster name.
    String clusterName = ""; // TODO: Update field(s).

    Dataproc service = createService();
    Diagnose request = service.projects().regions().clusters().diagnose(projectId, region, clusterName, requestBody);
    Operation response = request.execute();
    System.out.println(response);
  }

  public Dataproc createService() throws IOException, GeneralSecurityException {
    // TODO: This sample uses Application Default Credentials for authentication.
    // Install the gcloud CLI from https://cloud.google.com/sdk and run
    // `gcloud beta auth application-default login`
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    if (credential.createScopedRequired()) {
      credential =
          credential.createScoped(Arrays.asList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();

    return new Dataproc.Builder(httpTransport, jsonFactory, credential)
        .setApplicationName("Sample")
        .build();
  }

  public static void main(String[] args) throws IOException, GeneralSecurityException {
    try {
      new DataprocExample().run();
    } catch (IOException e) {
      System.out.println(e.getMessage());
    } catch (GeneralSecurityException e) {
      System.out.println(e.getMessage());
    }
=======
  public static void main(String[] args) throws IOException, GeneralSecurityException {

    // Authentication is provided by the 'gcloud' tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    // The createScopedRequired method returns true when running on GAE or a local developer
    // machine. In that case, the desired scopes must be passed in manually. When the code is
    // running in GCE, GKE or a Managed VM, the scopes are pulled from the GCE metadata server.
    // For more information, see
    // https://developers.google.com/identity/protocols/application-default-credentials
    if (credential.createScopedRequired()) {
      credential = credential.createScoped(Collections.singletonList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();
    Dataproc dataprocService = new Dataproc.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // TODO: Change placeholders below to appropriate parameter values for the 'diagnose' method:

    // * [Required] The ID of the Google Cloud Platform project that the cluster belongs to.
    String projectId = "{MY-PROJECT-ID}";

    // * [Required] The Cloud Dataproc region in which to handle the request.
    String region = "{MY-REGION}";

    // * [Required] The cluster name.
    String clusterName = "{MY-CLUSTER-NAME}";

    DiagnoseClusterRequest content = new DiagnoseClusterRequest();
    // TODO: Add code here to assign values to desired fields of the 'content' object

    Dataproc.Projects.Regions.Clusters.Diagnose request = dataprocService.projects().regions().clusters().diagnose(projectId, region, clusterName, content);
    Operation response = request.execute();

    // TODO: Add code here to process the 'response' object
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
  }
}
/*
 * BEFORE RUNNING:
 * ---------------
 * 1. If not already done, enable the Google Cloud Dataproc API
 *    and check the quota for your project at
 *    https://console.developers.google.com/apis/api/dataproc
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35
 * 2. Install the Java client library on Maven or Gradle. Check installation
=======
 * 2. This sample uses Application Default Credentials for authentication.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run
 *    'gcloud beta auth application-default login'
 * 3. Install the Java client library on maven or gradle. Check installation
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
 *    instructions at https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataproc/v1/java
 */
import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataproc.Dataproc;
import com.google.api.services.dataproc.Dataproc.Projects.Regions.Clusters.Get;
import com.google.api.services.dataproc.model.Cluster;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Arrays;


public class DataprocExample {
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35
  public void run() throws IOException, GeneralSecurityException {
    // [Required] The ID of the Google Cloud Platform project that the cluster belongs to.
    String projectId = ""; // TODO: Update field(s).

    // [Required] The Cloud Dataproc region in which to handle the request.
    String region = ""; // TODO: Update field(s).

    // [Required] The cluster name.
    String clusterName = ""; // TODO: Update field(s).

    Dataproc service = createService();
    Get request = service.projects().regions().clusters().get(projectId, region, clusterName);
    Cluster response = request.execute();
    System.out.println(response);
  }

  public Dataproc createService() throws IOException, GeneralSecurityException {
    // TODO: This sample uses Application Default Credentials for authentication.
    // Install the gcloud CLI from https://cloud.google.com/sdk and run
    // `gcloud beta auth application-default login`
=======
  public static void main(String[] args) throws IOException, GeneralSecurityException {

    // Authentication is provided by the 'gcloud' tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    if (credential.createScopedRequired()) {
      credential =
          credential.createScoped(Arrays.asList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35

    return new Dataproc.Builder(httpTransport, jsonFactory, credential)
        .setApplicationName("Sample")
        .build();
  }

  public static void main(String[] args) throws IOException, GeneralSecurityException {
    try {
      new DataprocExample().run();
    } catch (IOException e) {
      System.out.println(e.getMessage());
    } catch (GeneralSecurityException e) {
      System.out.println(e.getMessage());
    }
=======
    Dataproc dataprocService = new Dataproc.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // TODO: Change placeholders below to appropriate parameter values for the 'get' method:

    // * [Required] The ID of the Google Cloud Platform project that the cluster belongs to.
    String projectId = "{MY-PROJECT-ID}";

    // * [Required] The Cloud Dataproc region in which to handle the request.
    String region = "{MY-REGION}";

    // * [Required] The cluster name.
    String clusterName = "{MY-CLUSTER-NAME}";

    Dataproc.Projects.Regions.Clusters.Get request = dataprocService.projects().regions().clusters().get(projectId, region, clusterName);
    Cluster response = request.execute();

    // TODO: Add code here to process the 'response' object
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
  }
}
/*
 * BEFORE RUNNING:
 * ---------------
 * 1. If not already done, enable the Google Cloud Dataproc API
 *    and check the quota for your project at
 *    https://console.developers.google.com/apis/api/dataproc
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35
 * 2. Install the Java client library on Maven or Gradle. Check installation
=======
 * 2. This sample uses Application Default Credentials for authentication.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run
 *    'gcloud beta auth application-default login'
 * 3. Install the Java client library on maven or gradle. Check installation
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
 *    instructions at https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataproc/v1/java
 */
import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataproc.Dataproc;
import com.google.api.services.dataproc.Dataproc.Projects.Regions.Clusters.List;
import com.google.api.services.dataproc.model.Cluster;
import com.google.api.services.dataproc.model.ListClustersResponse;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Arrays;


public class DataprocExample {
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35
  public void run() throws IOException, GeneralSecurityException {
    // [Required] The ID of the Google Cloud Platform project that the cluster belongs to.
    String projectId = ""; // TODO: Update field(s).

    // [Required] The Cloud Dataproc region in which to handle the request.
    String region = ""; // TODO: Update field(s).

    Dataproc service = createService();
    List request = service.projects().regions().clusters().list(projectId, region);
=======
  public static void main(String[] args) throws IOException, GeneralSecurityException {

    // Authentication is provided by the 'gcloud' tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    // The createScopedRequired method returns true when running on GAE or a local developer
    // machine. In that case, the desired scopes must be passed in manually. When the code is
    // running in GCE, GKE or a Managed VM, the scopes are pulled from the GCE metadata server.
    // For more information, see
    // https://developers.google.com/identity/protocols/application-default-credentials
    if (credential.createScopedRequired()) {
      credential = credential.createScoped(Collections.singletonList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();
    Dataproc dataprocService = new Dataproc.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // TODO: Change placeholders below to appropriate parameter values for the 'list' method:

    // * [Required] The ID of the Google Cloud Platform project that the cluster belongs to.
    String projectId = "{MY-PROJECT-ID}";

    // * [Required] The Cloud Dataproc region in which to handle the request.
    String region = "{MY-REGION}";

    Dataproc.Projects.Regions.Clusters.List request = dataprocService.projects().regions().clusters().list(projectId, region);
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
    ListClustersResponse response;
    do {
      response = request.execute();
      if (response.getClusters() == null) {
        continue;
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35
=======

      for (Cluster cluster : response.getClusters()) {
        // TODO: Add code here to process each 'cluster' resource
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
      }
      for (Cluster item : response.getClusters()) {
        System.out.println(item);
      }
    } while (response.getNextPageToken() != null);
  }

  public Dataproc createService() throws IOException, GeneralSecurityException {
    // TODO: This sample uses Application Default Credentials for authentication.
    // Install the gcloud CLI from https://cloud.google.com/sdk and run
    // `gcloud beta auth application-default login`
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    if (credential.createScopedRequired()) {
      credential =
          credential.createScoped(Arrays.asList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();

    return new Dataproc.Builder(httpTransport, jsonFactory, credential)
        .setApplicationName("Sample")
        .build();
  }

  public static void main(String[] args) throws IOException, GeneralSecurityException {
    try {
      new DataprocExample().run();
    } catch (IOException e) {
      System.out.println(e.getMessage());
    } catch (GeneralSecurityException e) {
      System.out.println(e.getMessage());
    }
  }
}
/*
 * BEFORE RUNNING:
 * ---------------
 * 1. If not already done, enable the Google Cloud Dataproc API
 *    and check the quota for your project at
 *    https://console.developers.google.com/apis/api/dataproc
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35
 * 2. Install the Java client library on Maven or Gradle. Check installation
=======
 * 2. This sample uses Application Default Credentials for authentication.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run
 *    'gcloud beta auth application-default login'
 * 3. Install the Java client library on maven or gradle. Check installation
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
 *    instructions at https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataproc/v1/java
 */
import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataproc.Dataproc;
import com.google.api.services.dataproc.Dataproc.Projects.Regions.Clusters.Patch;
import com.google.api.services.dataproc.model.Cluster;
import com.google.api.services.dataproc.model.Operation;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Arrays;


public class DataprocExample {
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35
  public void run() throws IOException, GeneralSecurityException {
    // TODO: Assign desired fields.
    Cluster requestBody = new Cluster();

    // [Required] The ID of the Google Cloud Platform project the cluster belongs to.
    String projectId = ""; // TODO: Update field(s).

    // [Required] The Cloud Dataproc region in which to handle the request.
    String region = ""; // TODO: Update field(s).

    // [Required] The cluster name.
    String clusterName = ""; // TODO: Update field(s).

    Dataproc service = createService();
    Patch request = service.projects().regions().clusters().patch(projectId, region, clusterName, requestBody);
    Operation response = request.execute();
    System.out.println(response);
  }

  public Dataproc createService() throws IOException, GeneralSecurityException {
    // TODO: This sample uses Application Default Credentials for authentication.
    // Install the gcloud CLI from https://cloud.google.com/sdk and run
    // `gcloud beta auth application-default login`
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    if (credential.createScopedRequired()) {
      credential =
          credential.createScoped(Arrays.asList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();

    return new Dataproc.Builder(httpTransport, jsonFactory, credential)
        .setApplicationName("Sample")
        .build();
  }

  public static void main(String[] args) throws IOException, GeneralSecurityException {
    try {
      new DataprocExample().run();
    } catch (IOException e) {
      System.out.println(e.getMessage());
    } catch (GeneralSecurityException e) {
      System.out.println(e.getMessage());
    }
=======
  public static void main(String[] args) throws IOException, GeneralSecurityException {

    // Authentication is provided by the 'gcloud' tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    // The createScopedRequired method returns true when running on GAE or a local developer
    // machine. In that case, the desired scopes must be passed in manually. When the code is
    // running in GCE, GKE or a Managed VM, the scopes are pulled from the GCE metadata server.
    // For more information, see
    // https://developers.google.com/identity/protocols/application-default-credentials
    if (credential.createScopedRequired()) {
      credential = credential.createScoped(Collections.singletonList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();
    Dataproc dataprocService = new Dataproc.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // TODO: Change placeholders below to appropriate parameter values for the 'patch' method:

    // * [Required] The ID of the Google Cloud Platform project the cluster belongs to.
    String projectId = "{MY-PROJECT-ID}";

    // * [Required] The Cloud Dataproc region in which to handle the request.
    String region = "{MY-REGION}";

    // * [Required] The cluster name.
    String clusterName = "{MY-CLUSTER-NAME}";

    Cluster content = new Cluster();
    // TODO: Add code here to assign values to desired fields of the 'content' object to be changed

    Dataproc.Projects.Regions.Clusters.Patch request = dataprocService.projects().regions().clusters().patch(projectId, region, clusterName, content);
    Operation response = request.execute();

    // TODO: Add code here to process the 'response' object
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
  }
}
/*
 * BEFORE RUNNING:
 * ---------------
 * 1. If not already done, enable the Google Cloud Dataproc API
 *    and check the quota for your project at
 *    https://console.developers.google.com/apis/api/dataproc
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35
 * 2. Install the Java client library on Maven or Gradle. Check installation
=======
 * 2. This sample uses Application Default Credentials for authentication.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run
 *    'gcloud beta auth application-default login'
 * 3. Install the Java client library on maven or gradle. Check installation
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
 *    instructions at https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataproc/v1/java
 */
import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataproc.Dataproc;
import com.google.api.services.dataproc.Dataproc.Projects.Regions.Jobs.Cancel;
import com.google.api.services.dataproc.model.CancelJobRequest;
import com.google.api.services.dataproc.model.Job;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Arrays;


public class DataprocExample {
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35
  public void run() throws IOException, GeneralSecurityException {
    // TODO: Assign desired fields.
    CancelJobRequest requestBody = new CancelJobRequest();

    // [Required] The ID of the Google Cloud Platform project that the job belongs to.
    String projectId = ""; // TODO: Update field(s).

    // [Required] The Cloud Dataproc region in which to handle the request.
    String region = ""; // TODO: Update field(s).

    // [Required] The job ID.
    String jobId = ""; // TODO: Update field(s).

    Dataproc service = createService();
    Cancel request = service.projects().regions().jobs().cancel(projectId, region, jobId, requestBody);
    Job response = request.execute();
    System.out.println(response);
  }

  public Dataproc createService() throws IOException, GeneralSecurityException {
    // TODO: This sample uses Application Default Credentials for authentication.
    // Install the gcloud CLI from https://cloud.google.com/sdk and run
    // `gcloud beta auth application-default login`
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    if (credential.createScopedRequired()) {
      credential =
          credential.createScoped(Arrays.asList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();

    return new Dataproc.Builder(httpTransport, jsonFactory, credential)
        .setApplicationName("Sample")
        .build();
  }

  public static void main(String[] args) throws IOException, GeneralSecurityException {
    try {
      new DataprocExample().run();
    } catch (IOException e) {
      System.out.println(e.getMessage());
    } catch (GeneralSecurityException e) {
      System.out.println(e.getMessage());
    }
=======
  public static void main(String[] args) throws IOException, GeneralSecurityException {

    // Authentication is provided by the 'gcloud' tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    // The createScopedRequired method returns true when running on GAE or a local developer
    // machine. In that case, the desired scopes must be passed in manually. When the code is
    // running in GCE, GKE or a Managed VM, the scopes are pulled from the GCE metadata server.
    // For more information, see
    // https://developers.google.com/identity/protocols/application-default-credentials
    if (credential.createScopedRequired()) {
      credential = credential.createScoped(Collections.singletonList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();
    Dataproc dataprocService = new Dataproc.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // TODO: Change placeholders below to appropriate parameter values for the 'cancel' method:

    // * [Required] The ID of the Google Cloud Platform project that the job belongs to.
    String projectId = "{MY-PROJECT-ID}";

    // * [Required] The Cloud Dataproc region in which to handle the request.
    String region = "{MY-REGION}";

    // * [Required] The job ID.
    String jobId = "{MY-JOB-ID}";

    CancelJobRequest content = new CancelJobRequest();
    // TODO: Add code here to assign values to desired fields of the 'content' object

    Dataproc.Projects.Regions.Jobs.Cancel request = dataprocService.projects().regions().jobs().cancel(projectId, region, jobId, content);
    Job response = request.execute();

    // TODO: Add code here to process the 'response' object
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
  }
}
/*
 * BEFORE RUNNING:
 * ---------------
 * 1. If not already done, enable the Google Cloud Dataproc API
 *    and check the quota for your project at
 *    https://console.developers.google.com/apis/api/dataproc
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35
 * 2. Install the Java client library on Maven or Gradle. Check installation
=======
 * 2. This sample uses Application Default Credentials for authentication.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run
 *    'gcloud beta auth application-default login'
 * 3. Install the Java client library on maven or gradle. Check installation
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
 *    instructions at https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataproc/v1/java
 */
import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataproc.Dataproc;
import com.google.api.services.dataproc.Dataproc.Projects.Regions.Jobs.Delete;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Arrays;


public class DataprocExample {
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35
  public void run() throws IOException, GeneralSecurityException {
    // [Required] The ID of the Google Cloud Platform project that the job belongs to.
    String projectId = ""; // TODO: Update field(s).

    // [Required] The Cloud Dataproc region in which to handle the request.
    String region = ""; // TODO: Update field(s).

    // [Required] The job ID.
    String jobId = ""; // TODO: Update field(s).

    Dataproc service = createService();
    Delete request = service.projects().regions().jobs().delete(projectId, region, jobId);
    request.execute();
  }

  public Dataproc createService() throws IOException, GeneralSecurityException {
    // TODO: This sample uses Application Default Credentials for authentication.
    // Install the gcloud CLI from https://cloud.google.com/sdk and run
    // `gcloud beta auth application-default login`
=======
  public static void main(String[] args) throws IOException, GeneralSecurityException {

    // Authentication is provided by the 'gcloud' tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    if (credential.createScopedRequired()) {
      credential =
          credential.createScoped(Arrays.asList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35

    return new Dataproc.Builder(httpTransport, jsonFactory, credential)
        .setApplicationName("Sample")
        .build();
  }
=======
    Dataproc dataprocService = new Dataproc.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // TODO: Change placeholders below to appropriate parameter values for the 'delete' method:

    // * [Required] The ID of the Google Cloud Platform project that the job belongs to.
    String projectId = "{MY-PROJECT-ID}";

    // * [Required] The Cloud Dataproc region in which to handle the request.
    String region = "{MY-REGION}";

    // * [Required] The job ID.
    String jobId = "{MY-JOB-ID}";
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)

  public static void main(String[] args) throws IOException, GeneralSecurityException {
    try {
      new DataprocExample().run();
    } catch (IOException e) {
      System.out.println(e.getMessage());
    } catch (GeneralSecurityException e) {
      System.out.println(e.getMessage());
    }
  }
}
/*
 * BEFORE RUNNING:
 * ---------------
 * 1. If not already done, enable the Google Cloud Dataproc API
 *    and check the quota for your project at
 *    https://console.developers.google.com/apis/api/dataproc
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35
 * 2. Install the Java client library on Maven or Gradle. Check installation
=======
 * 2. This sample uses Application Default Credentials for authentication.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run
 *    'gcloud beta auth application-default login'
 * 3. Install the Java client library on maven or gradle. Check installation
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
 *    instructions at https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataproc/v1/java
 */
import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataproc.Dataproc;
import com.google.api.services.dataproc.Dataproc.Projects.Regions.Jobs.Get;
import com.google.api.services.dataproc.model.Job;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Arrays;


public class DataprocExample {
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35
  public void run() throws IOException, GeneralSecurityException {
    // [Required] The ID of the Google Cloud Platform project that the job belongs to.
    String projectId = ""; // TODO: Update field(s).

    // [Required] The Cloud Dataproc region in which to handle the request.
    String region = ""; // TODO: Update field(s).

    // [Required] The job ID.
    String jobId = ""; // TODO: Update field(s).

    Dataproc service = createService();
    Get request = service.projects().regions().jobs().get(projectId, region, jobId);
    Job response = request.execute();
    System.out.println(response);
  }

  public Dataproc createService() throws IOException, GeneralSecurityException {
    // TODO: This sample uses Application Default Credentials for authentication.
    // Install the gcloud CLI from https://cloud.google.com/sdk and run
    // `gcloud beta auth application-default login`
=======
  public static void main(String[] args) throws IOException, GeneralSecurityException {

    // Authentication is provided by the 'gcloud' tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    if (credential.createScopedRequired()) {
      credential =
          credential.createScoped(Arrays.asList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35

    return new Dataproc.Builder(httpTransport, jsonFactory, credential)
        .setApplicationName("Sample")
        .build();
  }

  public static void main(String[] args) throws IOException, GeneralSecurityException {
    try {
      new DataprocExample().run();
    } catch (IOException e) {
      System.out.println(e.getMessage());
    } catch (GeneralSecurityException e) {
      System.out.println(e.getMessage());
    }
=======
    Dataproc dataprocService = new Dataproc.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // TODO: Change placeholders below to appropriate parameter values for the 'get' method:

    // * [Required] The ID of the Google Cloud Platform project that the job belongs to.
    String projectId = "{MY-PROJECT-ID}";

    // * [Required] The Cloud Dataproc region in which to handle the request.
    String region = "{MY-REGION}";

    // * [Required] The job ID.
    String jobId = "{MY-JOB-ID}";

    Dataproc.Projects.Regions.Jobs.Get request = dataprocService.projects().regions().jobs().get(projectId, region, jobId);
    Job response = request.execute();

    // TODO: Add code here to process the 'response' object
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
  }
}
/*
 * BEFORE RUNNING:
 * ---------------
 * 1. If not already done, enable the Google Cloud Dataproc API
 *    and check the quota for your project at
 *    https://console.developers.google.com/apis/api/dataproc
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35
 * 2. Install the Java client library on Maven or Gradle. Check installation
=======
 * 2. This sample uses Application Default Credentials for authentication.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run
 *    'gcloud beta auth application-default login'
 * 3. Install the Java client library on maven or gradle. Check installation
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
 *    instructions at https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataproc/v1/java
 */
import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataproc.Dataproc;
import com.google.api.services.dataproc.Dataproc.Projects.Regions.Jobs.List;
import com.google.api.services.dataproc.model.Job;
import com.google.api.services.dataproc.model.ListJobsResponse;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Arrays;


public class DataprocExample {
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35
  public void run() throws IOException, GeneralSecurityException {
    // [Required] The ID of the Google Cloud Platform project that the job belongs to.
    String projectId = ""; // TODO: Update field(s).

    // [Required] The Cloud Dataproc region in which to handle the request.
    String region = ""; // TODO: Update field(s).

    Dataproc service = createService();
    List request = service.projects().regions().jobs().list(projectId, region);
=======
  public static void main(String[] args) throws IOException, GeneralSecurityException {

    // Authentication is provided by the 'gcloud' tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    // The createScopedRequired method returns true when running on GAE or a local developer
    // machine. In that case, the desired scopes must be passed in manually. When the code is
    // running in GCE, GKE or a Managed VM, the scopes are pulled from the GCE metadata server.
    // For more information, see
    // https://developers.google.com/identity/protocols/application-default-credentials
    if (credential.createScopedRequired()) {
      credential = credential.createScoped(Collections.singletonList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();
    Dataproc dataprocService = new Dataproc.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // TODO: Change placeholders below to appropriate parameter values for the 'list' method:

    // * [Required] The ID of the Google Cloud Platform project that the job belongs to.
    String projectId = "{MY-PROJECT-ID}";

    // * [Required] The Cloud Dataproc region in which to handle the request.
    String region = "{MY-REGION}";

    Dataproc.Projects.Regions.Jobs.List request = dataprocService.projects().regions().jobs().list(projectId, region);
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
    ListJobsResponse response;
    do {
      response = request.execute();
      if (response.getJobs() == null) {
        continue;
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35
=======

      for (Job job : response.getJobs()) {
        // TODO: Add code here to process each 'job' resource
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
      }
      for (Job item : response.getJobs()) {
        System.out.println(item);
      }
    } while (response.getNextPageToken() != null);
  }

  public Dataproc createService() throws IOException, GeneralSecurityException {
    // TODO: This sample uses Application Default Credentials for authentication.
    // Install the gcloud CLI from https://cloud.google.com/sdk and run
    // `gcloud beta auth application-default login`
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    if (credential.createScopedRequired()) {
      credential =
          credential.createScoped(Arrays.asList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();

    return new Dataproc.Builder(httpTransport, jsonFactory, credential)
        .setApplicationName("Sample")
        .build();
  }

  public static void main(String[] args) throws IOException, GeneralSecurityException {
    try {
      new DataprocExample().run();
    } catch (IOException e) {
      System.out.println(e.getMessage());
    } catch (GeneralSecurityException e) {
      System.out.println(e.getMessage());
    }
  }
}
/*
 * BEFORE RUNNING:
 * ---------------
 * 1. If not already done, enable the Google Cloud Dataproc API
 *    and check the quota for your project at
 *    https://console.developers.google.com/apis/api/dataproc
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35
 * 2. Install the Java client library on Maven or Gradle. Check installation
=======
 * 2. This sample uses Application Default Credentials for authentication.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run
 *    'gcloud beta auth application-default login'
 * 3. Install the Java client library on maven or gradle. Check installation
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
 *    instructions at https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataproc/v1/java
 */
import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataproc.Dataproc;
import com.google.api.services.dataproc.Dataproc.Projects.Regions.Jobs.Submit;
import com.google.api.services.dataproc.model.Job;
import com.google.api.services.dataproc.model.SubmitJobRequest;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Arrays;


public class DataprocExample {
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35
  public void run() throws IOException, GeneralSecurityException {
    // TODO: Assign desired fields.
    SubmitJobRequest requestBody = new SubmitJobRequest();

    // [Required] The ID of the Google Cloud Platform project that the job belongs to.
    String projectId = ""; // TODO: Update field(s).

    // [Required] The Cloud Dataproc region in which to handle the request.
    String region = ""; // TODO: Update field(s).

    Dataproc service = createService();
    Submit request = service.projects().regions().jobs().submit(projectId, region, requestBody);
    Job response = request.execute();
    System.out.println(response);
  }

  public Dataproc createService() throws IOException, GeneralSecurityException {
    // TODO: This sample uses Application Default Credentials for authentication.
    // Install the gcloud CLI from https://cloud.google.com/sdk and run
    // `gcloud beta auth application-default login`
=======
  public static void main(String[] args) throws IOException, GeneralSecurityException {

    // Authentication is provided by the 'gcloud' tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    if (credential.createScopedRequired()) {
      credential =
          credential.createScoped(Arrays.asList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35

    return new Dataproc.Builder(httpTransport, jsonFactory, credential)
        .setApplicationName("Sample")
        .build();
  }

  public static void main(String[] args) throws IOException, GeneralSecurityException {
    try {
      new DataprocExample().run();
    } catch (IOException e) {
      System.out.println(e.getMessage());
    } catch (GeneralSecurityException e) {
      System.out.println(e.getMessage());
    }
=======
    Dataproc dataprocService = new Dataproc.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // TODO: Change placeholders below to appropriate parameter values for the 'submit' method:

    // * [Required] The ID of the Google Cloud Platform project that the job belongs to.
    String projectId = "{MY-PROJECT-ID}";

    // * [Required] The Cloud Dataproc region in which to handle the request.
    String region = "{MY-REGION}";

    SubmitJobRequest content = new SubmitJobRequest();
    // TODO: Add code here to assign values to desired fields of the 'content' object

    Dataproc.Projects.Regions.Jobs.Submit request = dataprocService.projects().regions().jobs().submit(projectId, region, content);
    Job response = request.execute();

    // TODO: Add code here to process the 'response' object
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
  }
}
/*
 * BEFORE RUNNING:
 * ---------------
 * 1. If not already done, enable the Google Cloud Dataproc API
 *    and check the quota for your project at
 *    https://console.developers.google.com/apis/api/dataproc
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35
 * 2. Install the Java client library on Maven or Gradle. Check installation
=======
 * 2. This sample uses Application Default Credentials for authentication.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run
 *    'gcloud beta auth application-default login'
 * 3. Install the Java client library on maven or gradle. Check installation
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
 *    instructions at https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataproc/v1/java
 */
import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataproc.Dataproc;
import com.google.api.services.dataproc.Dataproc.Projects.Regions.Operations.Cancel;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Arrays;


public class DataprocExample {
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35
  public void run() throws IOException, GeneralSecurityException {
    // The name of the operation resource to be cancelled.
    String name = ""; // TODO: Update field(s).

    Dataproc service = createService();
    Cancel request = service.projects().regions().operations().cancel(name);
    request.execute();
  }

  public Dataproc createService() throws IOException, GeneralSecurityException {
    // TODO: This sample uses Application Default Credentials for authentication.
    // Install the gcloud CLI from https://cloud.google.com/sdk and run
    // `gcloud beta auth application-default login`
=======
  public static void main(String[] args) throws IOException, GeneralSecurityException {

    // Authentication is provided by the 'gcloud' tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    if (credential.createScopedRequired()) {
      credential =
          credential.createScoped(Arrays.asList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35

    return new Dataproc.Builder(httpTransport, jsonFactory, credential)
        .setApplicationName("Sample")
        .build();
  }
=======
    Dataproc dataprocService = new Dataproc.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // TODO: Change placeholders below to appropriate parameter values for the 'cancel' method:

    // * The name of the operation resource to be cancelled.
    String name = "projects/{MY-PROJECT}/regions/{MY-REGION}/operations/{MY-OPERATION}";
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)

  public static void main(String[] args) throws IOException, GeneralSecurityException {
    try {
      new DataprocExample().run();
    } catch (IOException e) {
      System.out.println(e.getMessage());
    } catch (GeneralSecurityException e) {
      System.out.println(e.getMessage());
    }
  }
}
/*
 * BEFORE RUNNING:
 * ---------------
 * 1. If not already done, enable the Google Cloud Dataproc API
 *    and check the quota for your project at
 *    https://console.developers.google.com/apis/api/dataproc
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35
 * 2. Install the Java client library on Maven or Gradle. Check installation
=======
 * 2. This sample uses Application Default Credentials for authentication.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run
 *    'gcloud beta auth application-default login'
 * 3. Install the Java client library on maven or gradle. Check installation
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
 *    instructions at https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataproc/v1/java
 */
import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataproc.Dataproc;
import com.google.api.services.dataproc.Dataproc.Projects.Regions.Operations.Delete;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Arrays;


public class DataprocExample {
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35
  public void run() throws IOException, GeneralSecurityException {
    // The name of the operation resource to be deleted.
    String name = ""; // TODO: Update field(s).

    Dataproc service = createService();
    Delete request = service.projects().regions().operations().delete(name);
    request.execute();
  }

  public Dataproc createService() throws IOException, GeneralSecurityException {
    // TODO: This sample uses Application Default Credentials for authentication.
    // Install the gcloud CLI from https://cloud.google.com/sdk and run
    // `gcloud beta auth application-default login`
=======
  public static void main(String[] args) throws IOException, GeneralSecurityException {

    // Authentication is provided by the 'gcloud' tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    if (credential.createScopedRequired()) {
      credential =
          credential.createScoped(Arrays.asList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35

    return new Dataproc.Builder(httpTransport, jsonFactory, credential)
        .setApplicationName("Sample")
        .build();
  }
=======
    Dataproc dataprocService = new Dataproc.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // TODO: Change placeholders below to appropriate parameter values for the 'delete' method:

    // * The name of the operation resource to be deleted.
    String name = "projects/{MY-PROJECT}/regions/{MY-REGION}/operations/{MY-OPERATION}";
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)

  public static void main(String[] args) throws IOException, GeneralSecurityException {
    try {
      new DataprocExample().run();
    } catch (IOException e) {
      System.out.println(e.getMessage());
    } catch (GeneralSecurityException e) {
      System.out.println(e.getMessage());
    }
  }
}
/*
 * BEFORE RUNNING:
 * ---------------
 * 1. If not already done, enable the Google Cloud Dataproc API
 *    and check the quota for your project at
 *    https://console.developers.google.com/apis/api/dataproc
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35
 * 2. Install the Java client library on Maven or Gradle. Check installation
=======
 * 2. This sample uses Application Default Credentials for authentication.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run
 *    'gcloud beta auth application-default login'
 * 3. Install the Java client library on maven or gradle. Check installation
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
 *    instructions at https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataproc/v1/java
 */
import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataproc.Dataproc;
import com.google.api.services.dataproc.Dataproc.Projects.Regions.Operations.Get;
import com.google.api.services.dataproc.model.Operation;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Arrays;


public class DataprocExample {
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35
  public void run() throws IOException, GeneralSecurityException {
    // The name of the operation resource.
    String name = ""; // TODO: Update field(s).

    Dataproc service = createService();
    Get request = service.projects().regions().operations().get(name);
    Operation response = request.execute();
    System.out.println(response);
  }

  public Dataproc createService() throws IOException, GeneralSecurityException {
    // TODO: This sample uses Application Default Credentials for authentication.
    // Install the gcloud CLI from https://cloud.google.com/sdk and run
    // `gcloud beta auth application-default login`
=======
  public static void main(String[] args) throws IOException, GeneralSecurityException {

    // Authentication is provided by the 'gcloud' tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    if (credential.createScopedRequired()) {
      credential =
          credential.createScoped(Arrays.asList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35

    return new Dataproc.Builder(httpTransport, jsonFactory, credential)
        .setApplicationName("Sample")
        .build();
  }

  public static void main(String[] args) throws IOException, GeneralSecurityException {
    try {
      new DataprocExample().run();
    } catch (IOException e) {
      System.out.println(e.getMessage());
    } catch (GeneralSecurityException e) {
      System.out.println(e.getMessage());
    }
=======
    Dataproc dataprocService = new Dataproc.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // TODO: Change placeholders below to appropriate parameter values for the 'get' method:

    // * The name of the operation resource.
    String name = "projects/{MY-PROJECT}/regions/{MY-REGION}/operations/{MY-OPERATION}";

    Dataproc.Projects.Regions.Operations.Get request = dataprocService.projects().regions().operations().get(name);
    Operation response = request.execute();

    // TODO: Add code here to process the 'response' object
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
  }
}
/*
 * BEFORE RUNNING:
 * ---------------
 * 1. If not already done, enable the Google Cloud Dataproc API
 *    and check the quota for your project at
 *    https://console.developers.google.com/apis/api/dataproc
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35
 * 2. Install the Java client library on Maven or Gradle. Check installation
=======
 * 2. This sample uses Application Default Credentials for authentication.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run
 *    'gcloud beta auth application-default login'
 * 3. Install the Java client library on maven or gradle. Check installation
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
 *    instructions at https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataproc/v1/java
 */
import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataproc.Dataproc;
import com.google.api.services.dataproc.Dataproc.Projects.Regions.Operations.List;
import com.google.api.services.dataproc.model.ListOperationsResponse;
import com.google.api.services.dataproc.model.Operation;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Arrays;


public class DataprocExample {
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35
  public void run() throws IOException, GeneralSecurityException {
    // The name of the operation collection.
    String name = ""; // TODO: Update field(s).

    Dataproc service = createService();
    List request = service.projects().regions().operations().list(name);
    ListOperationsResponse response;
    do {
      response = request.execute();
      if (response.getOperations() == null) {
        continue;
      }
      for (Operation item : response.getOperations()) {
        System.out.println(item);
      }
    } while (response.getNextPageToken() != null);
  }

  public Dataproc createService() throws IOException, GeneralSecurityException {
    // TODO: This sample uses Application Default Credentials for authentication.
    // Install the gcloud CLI from https://cloud.google.com/sdk and run
    // `gcloud beta auth application-default login`
=======
  public static void main(String[] args) throws IOException, GeneralSecurityException {

    // Authentication is provided by the 'gcloud' tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    if (credential.createScopedRequired()) {
      credential =
          credential.createScoped(Arrays.asList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();
<<<<<<< 87e3673f9830eb19419833f4430c7f10a733ae35

    return new Dataproc.Builder(httpTransport, jsonFactory, credential)
        .setApplicationName("Sample")
        .build();
  }
=======
    Dataproc dataprocService = new Dataproc.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // TODO: Change placeholders below to appropriate parameter values for the 'list' method:

    // * The name of the operation collection.
    String name = "{MY-NAME}";

    Dataproc.Projects.Regions.Operations.List request = dataprocService.projects().regions().operations().list(name);
    ListOperationsResponse response;
    do {
      response = request.execute();
      if (response.getOperations() == null)
        continue;

      for (Operation operation : response.getOperations()) {
        // TODO: Add code here to process each 'operation' resource
      }
>>>>>>> Add basic 3LO and API key auth support in discovery (#445)

  public static void main(String[] args) throws IOException, GeneralSecurityException {
    try {
      new DataprocExample().run();
    } catch (IOException e) {
      System.out.println(e.getMessage());
    } catch (GeneralSecurityException e) {
      System.out.println(e.getMessage());
    }
  }
}
