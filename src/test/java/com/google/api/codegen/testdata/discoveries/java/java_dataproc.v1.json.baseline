
/**
 * BEFORE RUNNING:
 * ---------------
 * 1. If not already done, enable the Google Cloud Dataproc API
 *    and check the quota for your project at
 *    https://console.developers.google.com/apis/api/dataproc
 * 2. This sample uses Application Default Credentials for authentication.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run
 *    `gcloud beta auth application-default login`
 * 3. Install the Java client library on maven or gradle. Check installation
 *    instructions at https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataproc/v1/java
 */

import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataproc.Dataproc;
import com.google.api.services.dataproc.model.Cluster;
import com.google.api.services.dataproc.model.Operation;
import com.google.gson.Gson;
import com.google.gson.JsonParser;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Collections;


public class DataprocExample {
  public static void main(String[] args) throws IOException, GeneralSecurityException {
    // Authentication is provided by the `gcloud` tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    // The createScopedRequired method returns true when running on GAE or a local developer
    // machine. In that case, the desired scopes must be passed in manually. When the code is
    // running in GCE, GKE or a Managed VM, the scopes are pulled from the GCE metadata server.
    // For more information, see
    // https://developers.google.com/identity/protocols/application-default-credentials
    if (credential.createScopedRequired()) {
      credential = credential.createScoped(Collections.singletonList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();

    Dataproc dataprocService = new Dataproc.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // [Required] The ID of the Google Cloud Platform project that the cluster belongs to.
    String projectId = "{MY-PROJECT-ID}"; // TODO: Update placeholder value(s).

    // [Required] The Cloud Dataproc region in which to handle the request.
    String region = "{MY-REGION}"; // TODO: Update placeholder value(s).

    // TODO: Assign values to the desired fields.
    Cluster requestBody = new Cluster();


    Dataproc.Projects.Regions.Clusters.Create request = dataprocService.projects().regions().clusters().create(projectId, region, requestBody);
    Operation response = request.execute();

    // TODO: Use response
    Gson gson = new GsonBuilder().setPrettyPrinting().create();
    System.out.println(gson.toJson(new JsonParser().parse(response.toString())));
  }
}
/**
 * BEFORE RUNNING:
 * ---------------
 * 1. If not already done, enable the Google Cloud Dataproc API
 *    and check the quota for your project at
 *    https://console.developers.google.com/apis/api/dataproc
 * 2. This sample uses Application Default Credentials for authentication.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run
 *    `gcloud beta auth application-default login`
 * 3. Install the Java client library on maven or gradle. Check installation
 *    instructions at https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataproc/v1/java
 */

import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataproc.Dataproc;
import com.google.api.services.dataproc.model.Operation;
import com.google.gson.Gson;
import com.google.gson.JsonParser;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Collections;


public class DataprocExample {
  public static void main(String[] args) throws IOException, GeneralSecurityException {
    // Authentication is provided by the `gcloud` tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    // The createScopedRequired method returns true when running on GAE or a local developer
    // machine. In that case, the desired scopes must be passed in manually. When the code is
    // running in GCE, GKE or a Managed VM, the scopes are pulled from the GCE metadata server.
    // For more information, see
    // https://developers.google.com/identity/protocols/application-default-credentials
    if (credential.createScopedRequired()) {
      credential = credential.createScoped(Collections.singletonList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();

    Dataproc dataprocService = new Dataproc.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // [Required] The ID of the Google Cloud Platform project that the cluster belongs to.
    String projectId = "{MY-PROJECT-ID}"; // TODO: Update placeholder value(s).

    // [Required] The Cloud Dataproc region in which to handle the request.
    String region = "{MY-REGION}"; // TODO: Update placeholder value(s).

    // [Required] The cluster name.
    String clusterName = "{MY-CLUSTER-NAME}"; // TODO: Update placeholder value(s).

    Dataproc.Projects.Regions.Clusters.Delete request = dataprocService.projects().regions().clusters().delete(projectId, region, clusterName);
    Operation response = request.execute();

    // TODO: Use response
    Gson gson = new GsonBuilder().setPrettyPrinting().create();
    System.out.println(gson.toJson(new JsonParser().parse(response.toString())));
  }
}
/**
 * BEFORE RUNNING:
 * ---------------
 * 1. If not already done, enable the Google Cloud Dataproc API
 *    and check the quota for your project at
 *    https://console.developers.google.com/apis/api/dataproc
 * 2. This sample uses Application Default Credentials for authentication.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run
 *    `gcloud beta auth application-default login`
 * 3. Install the Java client library on maven or gradle. Check installation
 *    instructions at https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataproc/v1/java
 */

import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataproc.Dataproc;
import com.google.api.services.dataproc.model.DiagnoseClusterRequest;
import com.google.api.services.dataproc.model.Operation;
import com.google.gson.Gson;
import com.google.gson.JsonParser;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Collections;


public class DataprocExample {
  public static void main(String[] args) throws IOException, GeneralSecurityException {
    // Authentication is provided by the `gcloud` tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    // The createScopedRequired method returns true when running on GAE or a local developer
    // machine. In that case, the desired scopes must be passed in manually. When the code is
    // running in GCE, GKE or a Managed VM, the scopes are pulled from the GCE metadata server.
    // For more information, see
    // https://developers.google.com/identity/protocols/application-default-credentials
    if (credential.createScopedRequired()) {
      credential = credential.createScoped(Collections.singletonList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();

    Dataproc dataprocService = new Dataproc.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // [Required] The ID of the Google Cloud Platform project that the cluster belongs to.
    String projectId = "{MY-PROJECT-ID}"; // TODO: Update placeholder value(s).

    // [Required] The Cloud Dataproc region in which to handle the request.
    String region = "{MY-REGION}"; // TODO: Update placeholder value(s).

    // [Required] The cluster name.
    String clusterName = "{MY-CLUSTER-NAME}"; // TODO: Update placeholder value(s).

    // TODO: Assign values to the desired fields.
    DiagnoseClusterRequest requestBody = new DiagnoseClusterRequest();


    Dataproc.Projects.Regions.Clusters.Diagnose request = dataprocService.projects().regions().clusters().diagnose(projectId, region, clusterName, requestBody);
    Operation response = request.execute();

    // TODO: Use response
    Gson gson = new GsonBuilder().setPrettyPrinting().create();
    System.out.println(gson.toJson(new JsonParser().parse(response.toString())));
  }
}
/**
 * BEFORE RUNNING:
 * ---------------
 * 1. If not already done, enable the Google Cloud Dataproc API
 *    and check the quota for your project at
 *    https://console.developers.google.com/apis/api/dataproc
 * 2. This sample uses Application Default Credentials for authentication.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run
 *    `gcloud beta auth application-default login`
 * 3. Install the Java client library on maven or gradle. Check installation
 *    instructions at https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataproc/v1/java
 */

import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataproc.Dataproc;
import com.google.api.services.dataproc.model.Cluster;
import com.google.gson.Gson;
import com.google.gson.JsonParser;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Collections;


public class DataprocExample {
  public static void main(String[] args) throws IOException, GeneralSecurityException {
    // Authentication is provided by the `gcloud` tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    // The createScopedRequired method returns true when running on GAE or a local developer
    // machine. In that case, the desired scopes must be passed in manually. When the code is
    // running in GCE, GKE or a Managed VM, the scopes are pulled from the GCE metadata server.
    // For more information, see
    // https://developers.google.com/identity/protocols/application-default-credentials
    if (credential.createScopedRequired()) {
      credential = credential.createScoped(Collections.singletonList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();

    Dataproc dataprocService = new Dataproc.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // [Required] The ID of the Google Cloud Platform project that the cluster belongs to.
    String projectId = "{MY-PROJECT-ID}"; // TODO: Update placeholder value(s).

    // [Required] The Cloud Dataproc region in which to handle the request.
    String region = "{MY-REGION}"; // TODO: Update placeholder value(s).

    // [Required] The cluster name.
    String clusterName = "{MY-CLUSTER-NAME}"; // TODO: Update placeholder value(s).

    Dataproc.Projects.Regions.Clusters.Get request = dataprocService.projects().regions().clusters().get(projectId, region, clusterName);
    Cluster response = request.execute();

    // TODO: Use response
    Gson gson = new GsonBuilder().setPrettyPrinting().create();
    System.out.println(gson.toJson(new JsonParser().parse(response.toString())));
  }
}
/**
 * BEFORE RUNNING:
 * ---------------
 * 1. If not already done, enable the Google Cloud Dataproc API
 *    and check the quota for your project at
 *    https://console.developers.google.com/apis/api/dataproc
 * 2. This sample uses Application Default Credentials for authentication.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run
 *    `gcloud beta auth application-default login`
 * 3. Install the Java client library on maven or gradle. Check installation
 *    instructions at https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataproc/v1/java
 */

import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataproc.Dataproc;
import com.google.api.services.dataproc.model.Cluster;
import com.google.api.services.dataproc.model.ListClustersResponse;
import com.google.gson.Gson;
import com.google.gson.JsonParser;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Collections;


public class DataprocExample {
  public static void main(String[] args) throws IOException, GeneralSecurityException {
    // Authentication is provided by the `gcloud` tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    // The createScopedRequired method returns true when running on GAE or a local developer
    // machine. In that case, the desired scopes must be passed in manually. When the code is
    // running in GCE, GKE or a Managed VM, the scopes are pulled from the GCE metadata server.
    // For more information, see
    // https://developers.google.com/identity/protocols/application-default-credentials
    if (credential.createScopedRequired()) {
      credential = credential.createScoped(Collections.singletonList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();

    Dataproc dataprocService = new Dataproc.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // [Required] The ID of the Google Cloud Platform project that the cluster belongs to.
    String projectId = "{MY-PROJECT-ID}"; // TODO: Update placeholder value(s).

    // [Required] The Cloud Dataproc region in which to handle the request.
    String region = "{MY-REGION}"; // TODO: Update placeholder value(s).

    Dataproc.Projects.Regions.Clusters.List request = dataprocService.projects().regions().clusters().list(projectId, region);

    Gson gson = new GsonBuilder().setPrettyPrinting().create();

    ListClustersResponse response;
    do {
      response = request.execute();
      if (response.getClusters() == null)
        continue;

      for (Cluster cluster : response.getClusters()) {
        // TODO: Use cluster
        System.out.println(gson.toJson(new JsonParser().parse(cluster.toString())));
      }

      request.setPageToken(response.getNextPageToken());
    } while (response.getNextPageToken() != null);
  }
}
/**
 * BEFORE RUNNING:
 * ---------------
 * 1. If not already done, enable the Google Cloud Dataproc API
 *    and check the quota for your project at
 *    https://console.developers.google.com/apis/api/dataproc
 * 2. This sample uses Application Default Credentials for authentication.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run
 *    `gcloud beta auth application-default login`
 * 3. Install the Java client library on maven or gradle. Check installation
 *    instructions at https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataproc/v1/java
 */

import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataproc.Dataproc;
import com.google.api.services.dataproc.model.Cluster;
import com.google.api.services.dataproc.model.Operation;
import com.google.gson.Gson;
import com.google.gson.JsonParser;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Collections;


public class DataprocExample {
  public static void main(String[] args) throws IOException, GeneralSecurityException {
    // Authentication is provided by the `gcloud` tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    // The createScopedRequired method returns true when running on GAE or a local developer
    // machine. In that case, the desired scopes must be passed in manually. When the code is
    // running in GCE, GKE or a Managed VM, the scopes are pulled from the GCE metadata server.
    // For more information, see
    // https://developers.google.com/identity/protocols/application-default-credentials
    if (credential.createScopedRequired()) {
      credential = credential.createScoped(Collections.singletonList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();

    Dataproc dataprocService = new Dataproc.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // [Required] The ID of the Google Cloud Platform project the cluster belongs to.
    String projectId = "{MY-PROJECT-ID}"; // TODO: Update placeholder value(s).

    // [Required] The Cloud Dataproc region in which to handle the request.
    String region = "{MY-REGION}"; // TODO: Update placeholder value(s).

    // [Required] The cluster name.
    String clusterName = "{MY-CLUSTER-NAME}"; // TODO: Update placeholder value(s).

    // TODO: Assign values to the desired fields to be changed.
    Cluster requestBody = new Cluster();


    Dataproc.Projects.Regions.Clusters.Patch request = dataprocService.projects().regions().clusters().patch(projectId, region, clusterName, requestBody);
    Operation response = request.execute();

    // TODO: Use response
    Gson gson = new GsonBuilder().setPrettyPrinting().create();
    System.out.println(gson.toJson(new JsonParser().parse(response.toString())));
  }
}
/**
 * BEFORE RUNNING:
 * ---------------
 * 1. If not already done, enable the Google Cloud Dataproc API
 *    and check the quota for your project at
 *    https://console.developers.google.com/apis/api/dataproc
 * 2. This sample uses Application Default Credentials for authentication.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run
 *    `gcloud beta auth application-default login`
 * 3. Install the Java client library on maven or gradle. Check installation
 *    instructions at https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataproc/v1/java
 */

import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataproc.Dataproc;
import com.google.api.services.dataproc.model.CancelJobRequest;
import com.google.api.services.dataproc.model.Job;
import com.google.gson.Gson;
import com.google.gson.JsonParser;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Collections;


public class DataprocExample {
  public static void main(String[] args) throws IOException, GeneralSecurityException {
    // Authentication is provided by the `gcloud` tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    // The createScopedRequired method returns true when running on GAE or a local developer
    // machine. In that case, the desired scopes must be passed in manually. When the code is
    // running in GCE, GKE or a Managed VM, the scopes are pulled from the GCE metadata server.
    // For more information, see
    // https://developers.google.com/identity/protocols/application-default-credentials
    if (credential.createScopedRequired()) {
      credential = credential.createScoped(Collections.singletonList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();

    Dataproc dataprocService = new Dataproc.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // [Required] The ID of the Google Cloud Platform project that the job belongs to.
    String projectId = "{MY-PROJECT-ID}"; // TODO: Update placeholder value(s).

    // [Required] The Cloud Dataproc region in which to handle the request.
    String region = "{MY-REGION}"; // TODO: Update placeholder value(s).

    // [Required] The job ID.
    String jobId = "{MY-JOB-ID}"; // TODO: Update placeholder value(s).

    // TODO: Assign values to the desired fields.
    CancelJobRequest requestBody = new CancelJobRequest();


    Dataproc.Projects.Regions.Jobs.Cancel request = dataprocService.projects().regions().jobs().cancel(projectId, region, jobId, requestBody);
    Job response = request.execute();

    // TODO: Use response
    Gson gson = new GsonBuilder().setPrettyPrinting().create();
    System.out.println(gson.toJson(new JsonParser().parse(response.toString())));
  }
}
/**
 * BEFORE RUNNING:
 * ---------------
 * 1. If not already done, enable the Google Cloud Dataproc API
 *    and check the quota for your project at
 *    https://console.developers.google.com/apis/api/dataproc
 * 2. This sample uses Application Default Credentials for authentication.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run
 *    `gcloud beta auth application-default login`
 * 3. Install the Java client library on maven or gradle. Check installation
 *    instructions at https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataproc/v1/java
 */

import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataproc.Dataproc;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Collections;


public class DataprocExample {
  public static void main(String[] args) throws IOException, GeneralSecurityException {
    // Authentication is provided by the `gcloud` tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    // The createScopedRequired method returns true when running on GAE or a local developer
    // machine. In that case, the desired scopes must be passed in manually. When the code is
    // running in GCE, GKE or a Managed VM, the scopes are pulled from the GCE metadata server.
    // For more information, see
    // https://developers.google.com/identity/protocols/application-default-credentials
    if (credential.createScopedRequired()) {
      credential = credential.createScoped(Collections.singletonList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();

    Dataproc dataprocService = new Dataproc.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // [Required] The ID of the Google Cloud Platform project that the job belongs to.
    String projectId = "{MY-PROJECT-ID}"; // TODO: Update placeholder value(s).

    // [Required] The Cloud Dataproc region in which to handle the request.
    String region = "{MY-REGION}"; // TODO: Update placeholder value(s).

    // [Required] The job ID.
    String jobId = "{MY-JOB-ID}"; // TODO: Update placeholder value(s).

    Dataproc.Projects.Regions.Jobs.Delete request = dataprocService.projects().regions().jobs().delete(projectId, region, jobId);
    request.execute();
  }
}
/**
 * BEFORE RUNNING:
 * ---------------
 * 1. If not already done, enable the Google Cloud Dataproc API
 *    and check the quota for your project at
 *    https://console.developers.google.com/apis/api/dataproc
 * 2. This sample uses Application Default Credentials for authentication.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run
 *    `gcloud beta auth application-default login`
 * 3. Install the Java client library on maven or gradle. Check installation
 *    instructions at https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataproc/v1/java
 */

import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataproc.Dataproc;
import com.google.api.services.dataproc.model.Job;
import com.google.gson.Gson;
import com.google.gson.JsonParser;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Collections;


public class DataprocExample {
  public static void main(String[] args) throws IOException, GeneralSecurityException {
    // Authentication is provided by the `gcloud` tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    // The createScopedRequired method returns true when running on GAE or a local developer
    // machine. In that case, the desired scopes must be passed in manually. When the code is
    // running in GCE, GKE or a Managed VM, the scopes are pulled from the GCE metadata server.
    // For more information, see
    // https://developers.google.com/identity/protocols/application-default-credentials
    if (credential.createScopedRequired()) {
      credential = credential.createScoped(Collections.singletonList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();

    Dataproc dataprocService = new Dataproc.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // [Required] The ID of the Google Cloud Platform project that the job belongs to.
    String projectId = "{MY-PROJECT-ID}"; // TODO: Update placeholder value(s).

    // [Required] The Cloud Dataproc region in which to handle the request.
    String region = "{MY-REGION}"; // TODO: Update placeholder value(s).

    // [Required] The job ID.
    String jobId = "{MY-JOB-ID}"; // TODO: Update placeholder value(s).

    Dataproc.Projects.Regions.Jobs.Get request = dataprocService.projects().regions().jobs().get(projectId, region, jobId);
    Job response = request.execute();

    // TODO: Use response
    Gson gson = new GsonBuilder().setPrettyPrinting().create();
    System.out.println(gson.toJson(new JsonParser().parse(response.toString())));
  }
}
/**
 * BEFORE RUNNING:
 * ---------------
 * 1. If not already done, enable the Google Cloud Dataproc API
 *    and check the quota for your project at
 *    https://console.developers.google.com/apis/api/dataproc
 * 2. This sample uses Application Default Credentials for authentication.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run
 *    `gcloud beta auth application-default login`
 * 3. Install the Java client library on maven or gradle. Check installation
 *    instructions at https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataproc/v1/java
 */

import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataproc.Dataproc;
import com.google.api.services.dataproc.model.Job;
import com.google.api.services.dataproc.model.ListJobsResponse;
import com.google.gson.Gson;
import com.google.gson.JsonParser;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Collections;


public class DataprocExample {
  public static void main(String[] args) throws IOException, GeneralSecurityException {
    // Authentication is provided by the `gcloud` tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    // The createScopedRequired method returns true when running on GAE or a local developer
    // machine. In that case, the desired scopes must be passed in manually. When the code is
    // running in GCE, GKE or a Managed VM, the scopes are pulled from the GCE metadata server.
    // For more information, see
    // https://developers.google.com/identity/protocols/application-default-credentials
    if (credential.createScopedRequired()) {
      credential = credential.createScoped(Collections.singletonList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();

    Dataproc dataprocService = new Dataproc.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // [Required] The ID of the Google Cloud Platform project that the job belongs to.
    String projectId = "{MY-PROJECT-ID}"; // TODO: Update placeholder value(s).

    // [Required] The Cloud Dataproc region in which to handle the request.
    String region = "{MY-REGION}"; // TODO: Update placeholder value(s).

    Dataproc.Projects.Regions.Jobs.List request = dataprocService.projects().regions().jobs().list(projectId, region);

    Gson gson = new GsonBuilder().setPrettyPrinting().create();

    ListJobsResponse response;
    do {
      response = request.execute();
      if (response.getJobs() == null)
        continue;

      for (Job job : response.getJobs()) {
        // TODO: Use job
        System.out.println(gson.toJson(new JsonParser().parse(job.toString())));
      }

      request.setPageToken(response.getNextPageToken());
    } while (response.getNextPageToken() != null);
  }
}
/**
 * BEFORE RUNNING:
 * ---------------
 * 1. If not already done, enable the Google Cloud Dataproc API
 *    and check the quota for your project at
 *    https://console.developers.google.com/apis/api/dataproc
 * 2. This sample uses Application Default Credentials for authentication.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run
 *    `gcloud beta auth application-default login`
 * 3. Install the Java client library on maven or gradle. Check installation
 *    instructions at https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataproc/v1/java
 */

import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataproc.Dataproc;
import com.google.api.services.dataproc.model.Job;
import com.google.api.services.dataproc.model.SubmitJobRequest;
import com.google.gson.Gson;
import com.google.gson.JsonParser;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Collections;


public class DataprocExample {
  public static void main(String[] args) throws IOException, GeneralSecurityException {
    // Authentication is provided by the `gcloud` tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    // The createScopedRequired method returns true when running on GAE or a local developer
    // machine. In that case, the desired scopes must be passed in manually. When the code is
    // running in GCE, GKE or a Managed VM, the scopes are pulled from the GCE metadata server.
    // For more information, see
    // https://developers.google.com/identity/protocols/application-default-credentials
    if (credential.createScopedRequired()) {
      credential = credential.createScoped(Collections.singletonList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();

    Dataproc dataprocService = new Dataproc.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // [Required] The ID of the Google Cloud Platform project that the job belongs to.
    String projectId = "{MY-PROJECT-ID}"; // TODO: Update placeholder value(s).

    // [Required] The Cloud Dataproc region in which to handle the request.
    String region = "{MY-REGION}"; // TODO: Update placeholder value(s).

    // TODO: Assign values to the desired fields.
    SubmitJobRequest requestBody = new SubmitJobRequest();


    Dataproc.Projects.Regions.Jobs.Submit request = dataprocService.projects().regions().jobs().submit(projectId, region, requestBody);
    Job response = request.execute();

    // TODO: Use response
    Gson gson = new GsonBuilder().setPrettyPrinting().create();
    System.out.println(gson.toJson(new JsonParser().parse(response.toString())));
  }
}
/**
 * BEFORE RUNNING:
 * ---------------
 * 1. If not already done, enable the Google Cloud Dataproc API
 *    and check the quota for your project at
 *    https://console.developers.google.com/apis/api/dataproc
 * 2. This sample uses Application Default Credentials for authentication.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run
 *    `gcloud beta auth application-default login`
 * 3. Install the Java client library on maven or gradle. Check installation
 *    instructions at https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataproc/v1/java
 */

import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataproc.Dataproc;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Collections;


public class DataprocExample {
  public static void main(String[] args) throws IOException, GeneralSecurityException {
    // Authentication is provided by the `gcloud` tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    // The createScopedRequired method returns true when running on GAE or a local developer
    // machine. In that case, the desired scopes must be passed in manually. When the code is
    // running in GCE, GKE or a Managed VM, the scopes are pulled from the GCE metadata server.
    // For more information, see
    // https://developers.google.com/identity/protocols/application-default-credentials
    if (credential.createScopedRequired()) {
      credential = credential.createScoped(Collections.singletonList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();

    Dataproc dataprocService = new Dataproc.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // The name of the operation resource to be cancelled.
    String name = "projects/{MY-PROJECT}/regions/{MY-REGION}/operations/{MY-OPERATION}"; // TODO: Update placeholder value(s).

    Dataproc.Projects.Regions.Operations.Cancel request = dataprocService.projects().regions().operations().cancel(name);
    request.execute();
  }
}
/**
 * BEFORE RUNNING:
 * ---------------
 * 1. If not already done, enable the Google Cloud Dataproc API
 *    and check the quota for your project at
 *    https://console.developers.google.com/apis/api/dataproc
 * 2. This sample uses Application Default Credentials for authentication.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run
 *    `gcloud beta auth application-default login`
 * 3. Install the Java client library on maven or gradle. Check installation
 *    instructions at https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataproc/v1/java
 */

import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataproc.Dataproc;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Collections;


public class DataprocExample {
  public static void main(String[] args) throws IOException, GeneralSecurityException {
    // Authentication is provided by the `gcloud` tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    // The createScopedRequired method returns true when running on GAE or a local developer
    // machine. In that case, the desired scopes must be passed in manually. When the code is
    // running in GCE, GKE or a Managed VM, the scopes are pulled from the GCE metadata server.
    // For more information, see
    // https://developers.google.com/identity/protocols/application-default-credentials
    if (credential.createScopedRequired()) {
      credential = credential.createScoped(Collections.singletonList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();

    Dataproc dataprocService = new Dataproc.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // The name of the operation resource to be deleted.
    String name = "projects/{MY-PROJECT}/regions/{MY-REGION}/operations/{MY-OPERATION}"; // TODO: Update placeholder value(s).

    Dataproc.Projects.Regions.Operations.Delete request = dataprocService.projects().regions().operations().delete(name);
    request.execute();
  }
}
/**
 * BEFORE RUNNING:
 * ---------------
 * 1. If not already done, enable the Google Cloud Dataproc API
 *    and check the quota for your project at
 *    https://console.developers.google.com/apis/api/dataproc
 * 2. This sample uses Application Default Credentials for authentication.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run
 *    `gcloud beta auth application-default login`
 * 3. Install the Java client library on maven or gradle. Check installation
 *    instructions at https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataproc/v1/java
 */

import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataproc.Dataproc;
import com.google.api.services.dataproc.model.Operation;
import com.google.gson.Gson;
import com.google.gson.JsonParser;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Collections;


public class DataprocExample {
  public static void main(String[] args) throws IOException, GeneralSecurityException {
    // Authentication is provided by the `gcloud` tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    // The createScopedRequired method returns true when running on GAE or a local developer
    // machine. In that case, the desired scopes must be passed in manually. When the code is
    // running in GCE, GKE or a Managed VM, the scopes are pulled from the GCE metadata server.
    // For more information, see
    // https://developers.google.com/identity/protocols/application-default-credentials
    if (credential.createScopedRequired()) {
      credential = credential.createScoped(Collections.singletonList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();

    Dataproc dataprocService = new Dataproc.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // The name of the operation resource.
    String name = "projects/{MY-PROJECT}/regions/{MY-REGION}/operations/{MY-OPERATION}"; // TODO: Update placeholder value(s).

    Dataproc.Projects.Regions.Operations.Get request = dataprocService.projects().regions().operations().get(name);
    Operation response = request.execute();

    // TODO: Use response
    Gson gson = new GsonBuilder().setPrettyPrinting().create();
    System.out.println(gson.toJson(new JsonParser().parse(response.toString())));
  }
}
/**
 * BEFORE RUNNING:
 * ---------------
 * 1. If not already done, enable the Google Cloud Dataproc API
 *    and check the quota for your project at
 *    https://console.developers.google.com/apis/api/dataproc
 * 2. This sample uses Application Default Credentials for authentication.
 *    If not already done, install the gcloud CLI from
 *    https://cloud.google.com/sdk/ and run
 *    `gcloud beta auth application-default login`
 * 3. Install the Java client library on maven or gradle. Check installation
 *    instructions at https://github.com/google/google-api-java-client.
 *    On other build systems, you can add the jar files to your project from
 *    https://developers.google.com/resources/api-libraries/download/dataproc/v1/java
 */

import com.google.api.client.googleapis.auth.oauth2.GoogleCredential;
import com.google.api.client.googleapis.javanet.GoogleNetHttpTransport;
import com.google.api.client.http.HttpTransport;
import com.google.api.client.json.JsonFactory;
import com.google.api.client.json.jackson2.JacksonFactory;
import com.google.api.services.dataproc.Dataproc;
import com.google.api.services.dataproc.model.ListOperationsResponse;
import com.google.api.services.dataproc.model.Operation;
import com.google.gson.Gson;
import com.google.gson.JsonParser;
import java.io.IOException;
import java.security.GeneralSecurityException;
import java.util.Collections;


public class DataprocExample {
  public static void main(String[] args) throws IOException, GeneralSecurityException {
    // Authentication is provided by the `gcloud` tool when running locally
    // and by built-in service accounts when running on GAE, GCE, or GKE.
    GoogleCredential credential = GoogleCredential.getApplicationDefault();

    // The createScopedRequired method returns true when running on GAE or a local developer
    // machine. In that case, the desired scopes must be passed in manually. When the code is
    // running in GCE, GKE or a Managed VM, the scopes are pulled from the GCE metadata server.
    // For more information, see
    // https://developers.google.com/identity/protocols/application-default-credentials
    if (credential.createScopedRequired()) {
      credential = credential.createScoped(Collections.singletonList("https://www.googleapis.com/auth/cloud-platform"));
    }

    HttpTransport httpTransport = GoogleNetHttpTransport.newTrustedTransport();
    JsonFactory jsonFactory = JacksonFactory.getDefaultInstance();

    Dataproc dataprocService = new Dataproc.Builder(httpTransport, jsonFactory, credential)
      .setApplicationName("Google Cloud Platform Sample")
      .build();

    // The name of the operation collection.
    String name = "{MY-NAME}"; // TODO: Update placeholder value(s).

    Dataproc.Projects.Regions.Operations.List request = dataprocService.projects().regions().operations().list(name);

    Gson gson = new GsonBuilder().setPrettyPrinting().create();

    ListOperationsResponse response;
    do {
      response = request.execute();
      if (response.getOperations() == null)
        continue;

      for (Operation operation : response.getOperations()) {
        // TODO: Use operation
        System.out.println(gson.toJson(new JsonParser().parse(operation.toString())));
      }

      request.setPageToken(response.getNextPageToken());
    } while (response.getNextPageToken() != null);
  }
}
